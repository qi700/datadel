大数据的潜在影响及制度需求
由于大数据刚刚热起来，所以不必着急下结论。当年IT刚刚发展时，研究增长问题的权威罗伯特·索洛(Robert Solow)教授提出了一个“索洛悖论”：“我们到处都看得见计算机，就是在生产率统计方面却看不见。”直到过了15年，到2002年时，他才公开承认说：“我现在发现IT可能对生产率是有贡献的。”对大数据的研究，可能也需要一个很长的时间才能确认价值所在。　　关于大数据，我有几点看法：第一，由于大数据刚刚热起来，所以不必着急下结论。当年IT刚刚发展时，研究增长问题的权威罗伯特·索洛(Robert Solow)教授提出了一个“索洛悖论”：“我们到处都看得见计算机，就是在生产率统计方面却看不见。”直到过了15年，到2002年时，他才公开承认说：“我现在发现IT可能对生产率是有贡献的。”对大数据的研究，可能也需要一个很长的时间才能确认价值所在。　　第二，可能性不等于可行性。现在有种观点：“到底是大数据还是大忽悠？什么都讲是大数据。”其实是说现在讲的或者设想的都是“可能性”而不是“可行性”。“可行性”要到什么时间？现在还看不出来。它需要合理的制度安排，还需要企业、公司不断地进行商业实践、不断试错，以及科研工作者对大数据分析技术的不断改进。　　第三，目前的研究主要还是提问阶段，而不是解决问题。当然，如果能提出好的问题，这也算是一个研究的好成果。　　一、大数据的产生、内涵及争议　　首先，大数据何来？实际上大数据一直存在，存在于不同的地方。比如每个人都包涵着很多数据：身高、体重等等，包括观点、思想。但是过去没有互联网，所以这些数据很难得到应用。数据分析在很早就存在。春秋时孙膑就曾用对方营地做灶的数量来判断对方军队的数量，从而指导打仗。不过，当时这样的数据非常少，有这个利用能力的人才会成为时代的智者。　　然而，现在的情况不太一样了。互联网应用以来，从2005年开始，数据在不断地增长，到2010年以后基本上是一个指数增长的过程，到2013年时已经超过4个ZB，每年的增长率超过50%。这就是一个从量变到质变的过程。　　之前为什么不说大数据呢？这是个相对的概念，到某一天它的增长速度突然特别快的时候，“大”的概念就蹦出来了。所以它其实不是一个严格的学术概念，只是因为在量变的过程中大家感觉到这种质变，或者感觉它里面有价值。　　主要的数据来源　　主要的数据来源，总的来讲有两个方面：　　第一，物的数据。　　其中比较有代表性的，就是由传感器组成的物联网，这个概念是IBM(189.64, 0.49, 0.26%)在2009年提出来的一种商业模式，当时叫“智慧地球”。就是把传感器装到不同的物体上面，然后展现它的各种数据，比如温度、湿度、压力等等。物联网这几年的增长速度比较快，能达到20%－30%的增长速度，物的数据在不断地增加。　　第二，人的数据。　　其中最典型的是移动互联网的发展。近年来移动互联网占整个互联网流量的比例越来越高，移动端尤其是用户自己发送数据的比例大大提高了，这也是大数据非常重要的一个来源。通过这些移动端的数据，就可以判断一个人的职业、兴趣、品质或者其每时每刻的位置，就是说，靠这些数据能很精确地找到每个人的各种情况。　　数据为什么会突然大量增加？一是IT成本下降，此外，跟这两年云计算使用率的上升有很大的关系。从亚马逊(313.65, 6.59, 2.15%)弹性云存储的文件量增长情况可见，从2006年到2013年增加的量是非常显著的，到2013年二季度时已经有2万亿数量文件存储在弹性云上。　　那么，云计算为什么会降低IT成本？基于我们之前一年的实践研究数据可知，首先，从需求方来看，过去购买一些硬件包括服务器、电脑等等，成本比较昂贵。但是云计算系统把IT资源集中起来后，以租用的方式来使用，就比买它的价格便宜很多。从供给的角度来看，当把所有的IT资源集中起来以后，会有非常明显的规模经济，因为同时运营很多台服务器(当然这是基于技术)，其成本会显著下降。　　这里还有一个范围经济的概念：当把IT资源集中起来以后，不单有规模经济，还经营了多种的资源。比如说，搜索可能需要占很多CPU的计算资源，但是磁盘资源可能没那么多；电子邮件可能相反。当它集中运用的时候，可以同时得到这两种效率。所以，这也是云计算对IT成本下降的一个贡献。　　大数据四“V”　　关于大数据的定义，现在谈得最多的就是所谓的四个“V”，也有五个、六个“V”之说。IDC(互联网数据中心)归结的四个“V”中，第一个就是它的实际规模。从早先的KB，到TB，一直到后来的PB、EB，数据的量在不断地增加，这是一个表面的现象。　　第二个“V”是多样的数据类型，尤其是里面包涵了大量的非结构化的数据。什么是非结构化的数据？比如在网上发一条微信，这句话本身没法拿来做统计或计量分析，但是可以在里面提取结构化数据进行分析。这样的数据反而占数据量很重要的一部分。　　第三个“V”讲的是价值，有两点：一个是价值大，大数据带来各种可能性；另外一个比较重要的是，它虽然量很大、价值也很大，但是密度很低。在互联网上抓取的1GB的大数据，里面有用的可能只有千分之一、万分之一，或者百万分之一，所以，挖掘和分析比原来更加困难。　　第四个“V”就是动态数据的快速处理。在这方面云计算的贡献比较大，这里比较核心的，也是大数据将来能不能从“可能”到“可行”转变的两个要素，即：非结构化和低密度。这两者其实互相相关，如果技术上能解决怎么分析非结构化数据、怎么从低密度价值里面提取数据的价值，那么大数据的应用可能就会有一个飞跃的增长。所以，我觉得非结构化和低密度可能是大数据的核心东西。　　那么大数据是什么呢？如果管中窥豹，从点上去看它，首先，大数据的“大”肯定是一个相对的概念，它不是一个绝对的概念。另外，它更不是一个学术性的概念，而且这里面需要关注的就是非结构化的数据可能占大数据的主要部分，尤其是来自于网民的交互式的数据可能是未来大数据的主体之一。　　从分析方法来看，过去得到数据或者统计的方法是抽样，然后利用概率论和随机过程等数学的方法来推理，从而达到目的，推测得出全部数据。现在有这种可能性，如果成本降得比较低的话，就可以获得全部的数据。　　对大数据的质疑　　当然，对大数据也有非常多的质疑。首先，有人提出“大数据陷阱”。数据是不是越多越好？实际上，对任何企业或个体来说，数据肯定不是越多越好，肯定有一个最优的数据量，因为要分析大量的数据，方法是不是可能？分析成本有多高？这个大量的数据包含的价值有多大？所以，对每一个企业都有一个最优的数据量，就是从拿到的数据范围里面获得的价值和为了获得这些价值而付出的分析成本，它们两个接近相等的时候，可能就是最优数据量。　　再就是，MIT的凯特·克劳福德(Kate Crawford)教授提出“大数据中存在偏见和盲区”：数据在生成或采集的过程中并不都是平等的，大数据集存在“信号问题”，即某些民众和社区被忽略或未得到充分体现。这个比较典型，比如说，国内现在有6亿多网民，有时候不能用6亿的数据去判断13亿人的状态，因为这个过程不是靠抽样得到的。　　第三个问题就是“泄露个人隐私成为日益严重的担忧”。在我们不知情时，数据就被人拿走了，这是很可怕的事。