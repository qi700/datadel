亦能覆舟！为人工智能敲响警钟
日前，26位专家学者就人工智能安全问题联合发布了一份报告，这份名为《人工智能的恶意用途：预测、预防和缓解》的报告，呼吁大家关注危险人工智能的崛起，并为之做好充分的准备。(文末含LaTeX福利）
报告指出恶意利用人工智能将导致潜在的安全威胁，并提出了多种预测、预防和缓解威胁的方式建议。报告分析了在未来5到10年内，人工智能在数字安全、物理安全和政治安全领域可能产生的影响，并向研究者等领域相关人员提出了四条应对建议。此外，报告还提及了多个有前景的研究领域，以促进人工智能安全问题的防治解决。最后，报告还讨论了安全行为中攻守双方的平衡问题，但未提出明确的解决方案。
本次报告撰写者来自于14家顶尖人工智能研究及安全组织，它们包括：非营利组织OpenAI（不久前Open AI宣布联合创始人Elon Musk将离开董事会，但会继续为该组织提供支持和建议）、剑桥大学生存风险研究中心（CSER）、牛津大学人类未来研究所（FHI）、新美国安全中心（CNAS）、电子前沿基金会（EFF）等。
关于人工智能的分析报告不少，如白宫出台的《国家人工智能研究与发展策略规划》、我国四部委联合发印的《“互联网+”人工智能三年行动实施方案》、乌镇智库推出的《乌镇指数：全球人工智能发展报告2017》等等。但这些报告更多地侧重于人工智能的光明前景，而撰写此次报告的专家们却认为：
人们对人工智能被恶意使用的方式与可能性，
从未给予过足够重视，这是值得担忧的。
乌镇报告中的人工智能领域大学排名（Top20）
人工智能将如何影响现有的安全格局
1、人工智能会扩大现有的安全威胁。通过AI系统的拓展使用，那些通常需要人力、智力和专业知识的任务将更容易完成，令攻击成本大大降低。这会直接导致被攻击人群的范围迅速扩大，增加更多可攻击的潜在目标，其攻击速度也会攀升。
2、人工智能会引入新的安全威胁。通过 AI 系统，攻击者可以完成以往难以做到的新型安全攻击。另一方面，所开发的AI系统本身也会因为开发漏洞而增加被攻击利用的可能。
3、人工智能会改变安全威胁的典型特征。伴随着AI的迅速普及应用，安全攻击将会更加高效、富于针对性，并且难以溯因防守。这将很大程度上改变网络安全问题的相关特征。
人工智能的应用前景
资料来源：《国家人工智能研究与发展策略规划》
报告中还详细分析了数字安全、物理安全和政治安全这三个领域，并通过一些代表性的例子说明了其中潜在的安全威胁：
数字安全：传统的网络攻击任务中，攻击规模和攻击效率之间往往不能两全，而使用AI来执行这些任务，将突破这一局限。比如，它会增大“劳动密集型”网络攻击（如鱼叉式网络钓鱼）的威胁程度。此外，人工智能还会促成各种新型安全攻击：利用人类弱点，例如通过语音合成进行身份冒充；利用现有的软件漏洞进行自动黑客攻击；通过对抗性样本和数据下毒攻击AI系统，等等。
物理安全：使用 AI 来自动执行如无人机或其他物理系统（如自主武器系统）有关的攻击任务。此外，AI 也可能会催生新型的攻击方式，包括破坏物理网络（如导致自动驾驶车辆瘫痪故障）、可实现远程入侵的物理系统（如成千上万的微型无人机）。
政治安全：使用AI进行自动地监控（如分析所收集的数据）、劝诱（如有针对性地宣传）、欺诈（如窜改影像资料），这可能会导致更严重的隐私侵犯和社交操纵。此外，利用AI的学习能力，在现有数据的基础上，分析掌握人们的行为、情绪、信念，这也是一大潜在危险。这些手段被威权国家采用将尤其令人忧心。当然，不可否认，它也会同时危及民主国家（如是否还能保证公开辩论的真实性）。
Musk领导的特斯拉正在积极推进无人驾驶技术
为应对这些威胁挑战，报告提出了四项建议：
密切合作：决策者应与技术研究人员保持密切合作，防止人工智能被恶意应用。
严阵以待：人工智能领域的相关人员应审慎对待他们工作的双重性，并在有害应用可预见时迅速采取措施，积极与相关行为者接触。
制定方案：应采用更多成熟的方案，以便在研究领域确立最佳的实践方法，来解决AI的双刃剑问题。就像解决计算机安全一样来考虑哪些地方可以应用 AI。
扩大讨论：积极拓宽该讨论的参与者范围。
质疑炒作
对于这份报告，Gigaom网站评论员Jon Collins认为，它缺乏对风险的“性质讨论”，他批评道：“……风险是个数学结构，是概率和影响的产物。而报告里却一而再地使用‘好像是’等字眼来描述AI的进程、潜在目标和预期结果。好像除此之外，报告别无他物。”
他提到，报告很好地进入了公共舆论，这是它值得称道的地方。但是这还远远不够的，因为AI周围早已布满了“炒作与反炒作”。他指出：
报告给出的分析、建议实际上都在指引着更多的资源流向AI领域，而这是学者和咨询公司常用的一种策略。
“也许第四个建议才最能说明问题，即他们在寻求更多人的关注和参与”，Jon Collins评论道。