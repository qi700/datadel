改变移动互联网的新型人机交互技术
移动互联网正在飞速发展，并改变着人们的生活，而智能终端是发展各种移动互联网应用的关键，新型的人机交互方式不仅改变着智能终端，也改变着移动互联网的未来。对近几年的新型人机交互方式及其关键技术进行了全面分析，并对未来趋势进行了初步的总结。   1.前言    随着移动互联网的飞速发展。用户体验成为移动互联网应用普及和加速渗透的关键，而“人机交互”（human-computer interaction）成为用户体验移动互联网应用的第一关口。人机交互是通过输入、输出设备，实现人与终端设备交互的手段，包括人通过输入设备给机器输入交互信息、机器通过输出或显示设备给人提供交互信息，最终实现人机互动。     从iPhone的多点触控技术、Siri语音控制技术到谷歌眼镜。新型人机交互技术彻底地颠覆了传统手机定义，使智能终端具有了“听觉”、“视觉”、“触觉”，突破了移动终端各种物理局限，掀起了移动互联网的一波又一波发展高潮，极大地改善了移动智能终端的用户体验。降低了应用门槛。基于新型交互技术形成了一个又一个产业开发生态圈。挖掘出移动互联网无穷无尽的价值。新型交互技术已成为影响智能终端和移动互联网应用发展方向的一个关键环节。为此。本文主要对近几年移动互联网主要的新型交互技术进行了一个全面的总结和分析。   2.屏幕触控交互技术    手机键盘是传统手机必备的配件，而屏幕触控交互技术的应用颠覆了手机的定义。屏幕触控交互为人机触觉交互提供有效的信息输入功能，并为用户提供了简单、方便、自然的人机交互方式。利用这种技术，用户只要用手指轻轻地触碰智能终端设备触摸显示屏上的图符或文字就能实现对终端的操作。触摸屏系统一般由触摸检测部件和触摸屏控制器两个部分组成，触摸检测部件安装在显示器屏幕前面，用于检测用户触摸位置。然后将相关信息传送至触摸屏控制器；而触摸屏控制器的主要作用是从触摸点检测装置上接收触摸信息，并将它转换成触点坐标。    触控技术包括单点触控和多点触控。单点触控一次只能向控制器传达一个触点信息：多点触控技术能够记录同时发生的多点触控信息，使智能终端系统可以同时响应操作者在屏幕上的多点操作，从而实现屏幕识别人的多个手指同时做的点击、触控动作。    多点触控技术始于1982年多伦多大学发明的感应食指指压的多点触控屏幕技术。同年，贝尔实验室发表了首份探讨触控技术的学术文献。1984年，贝尔实验室研制出一种能够以多于一只手控制改变画面的触屏。1999年，Fingerworks公司推出了多点触控iGesture板和多点触控键盘，并于2005年被苹果电脑收购。2006年，纽约大学的Jefferson Y Han教授领导研发的新型触摸屏可由双手同时操作，支持多人同时操作，而且响应时间非常短——小于0.1s。2007年，苹果公司及微软公司分别发布了应用多点触控技术的产品及计划——iPhone及Surface Computing，令该技术开始进入主流的应用。    多点触控技术目前有两种：多点触摸识别手势方向(multi-touch gesture)和多点触摸识别手指位置(multi-toucha11-point)。多点触摸识别手势方向是指多个手指触摸时，不能判断出它们的具体位置，但可以判断它们的相对运动方向，从而进行缩放、平移、旋转等操作：多点触摸识别手指位置可以辨识多个手指同时触摸时各触摸点的具体位置，后者难度远大于前者。苹果iPhone采用的是交互电容式触摸屏技术，从而实现多点触摸识别手指位置，并引领智能终端进入触控时代。未来电容屏将成为主要趋势。更灵敏、更薄将成为触控屏的发展方向。   3.语音交互技术    语音是人类最自然、最便捷的沟通方式。所有信息设备“能听会说”是必然的趋势。随着移动互联网的快速发展．无线带宽大幅提升和云计算技术体系不断成熟，为语音交互技术应用到移动智能终端上创造了条件。    2010年10月28日。科大讯飞在业界率先发布“语音云”，为手机、汽车、智能家电等终端提供高质量语音合成、搜索听写交互服务。目前，科大讯飞语音识别和理解率均能够达到90％(高于手写识别率的88％)，自然度达到了4.2，开发合作伙伴已达4000家。2011年10月。苹果公司发布了产品iPhone 4S。Siri是iPhone 4S上应用的一项语音控制功能，也被称为虚拟个人助理(VPA)。利用Siri，用户可以通过手机读短信、介绍餐厅、询问天气、语音设置闹钟等。Siri可以支持自然语言输入，并且可以调用系统自带的天气预报、日程安排搜索资料等应用，还能够不断学习新的声音和语调．提供对话式应答，使得“语音控制”成为当年智能终端产业最受关注的方向。    语音控制主要包括语音识别、语义理解、语音合成等关键技术。其中，语音识别是指将语音中的内容、说话人、语种等信息识别出来，目前端云结合的语音识别实现方式是主流，一般是由终端负责采集语音，并压缩编码传送至云端，再借助云端强大的计算资源进行识别解码。识别结果将被进一步传送至后端语义理解等功能模块进行处理。语音合成是将文字或信息转化为自然流畅的语音。早期主要是采用参数合成方法。后来随着计算机技术的发展又出现了波形拼接的合成方法。随着基音同步叠加(PSOLA)方法的提出，基于时域波形拼接方法合成的语音的音色和自然度大大提高，如讯飞的商用波形拼接语音合成系统。效果已经近了播音员水平。    根据用户的使用目的，语音交互技术可以在移动互联网多种场景中应用，如语音控制、语音聊天、语音翻译、语音搜索、语音导航等。目前，语音识别植入手机操作系统底层已是大势所趋，语音控制技术的发展，使用户可以用语音直接获得移动互联网服务，降低了移动互联网业务的使用难度，加速移动互联网应用的推广，成为未来移动互联网入口之一。基于语义理解的语音交互技术及其应用的研究将是业界未来重要的研究和创新方向。   4.移动增强现实技术    虚拟现实(vinual reality，VR)是指利用电脑模拟产生一个三维空间的虚拟世界，提供使用者关于视觉、听觉、触觉等感官的模拟，让使用者如同身临其境一般，可以及时地、没有限制地观察三维空间内的事物。增强现实faugmentreality，AR)，也被称为混合现实，是在虚拟现实技术基础上发展起来的一种综合了计算机视觉、图形学、图像处理、多传感器技术、显示技术的新兴计算机应用和人机交互技术。增强现实技术利用计算机产生的虚拟信息对用户所观察的真实环境进行融合，真实环境和虚拟物体实时地叠加到了同一个画面或空间，拓展和增强用户对周围世界的感知。实现双向互动。    随着移动互联网技术的成熟．各种智能终端平台相继推出。一大批以移动终端定位与状态感知、多媒体信息处理与展现技术为基础的增强现实应用开始涌现。称为移动增强现实(mobile augmented reality，MobAR))应用。目前，移动增强现实典型应用场景大致可分为以下几类：游览指南场景，主要应用于文化古迹，当游客使用以增强现实技术为基础的导游软件时，只需用手机摄像头对准眼前古迹或废墟。手机里的全球定位系统和图像识别软件就能判断位置。从而从游客所在的视角，在手机上显示这处古迹在全盛时期的样貌，还能展示遗址上残缺部分的虚拟重构；游戏应用场景，游戏应用利用设备自带的摄像头捕捉周围的实时画面，利用陀螺仪和重力感应来判断玩家的动作、方向和位置变化，玩家则需要在实境中对游戏虚拟对象进行击打或控制：电子商务场景，如近年来在北京地铁站出现的虚拟购物超市。消费者只要通过手机拍摄想要购买的物品并发送给服务商，就可以享受送货上门的服务。    支撑移动增强现实的关键技术主要包括：目标特征提取技术、目标跟踪注册技术、内容实时渲染技术。随着用户对移动增强现实应用体验要求日益提高，必将对移动终端、增强现实平台的媒体计算能力提出更大的挑战，在复杂场景(如光线变化、快速运动)下的目标识别技术、将终端摄像头和终端其他多种传感器结合的目标追踪方法将是未来技术研究的方向。   5.传感感应技术    由于移动终端的便携性和智能性逐步提升，传感感应技术被逐步引入到智能手机中，目前智能终端中已引入重力感应器、距离传感器、电子罗盘、光线传感器、陀螺仪等多种感应设备。    (1)重力感应器    手机重力感应是利用“压电效应”实现的，通过对力敏感的传感器，感受手机在变换姿势时重心的变化，使手机光标变化位置，利用重力传感器水平测量仪可使测量精度达到0.002弧度。还可通过预先编程、多个传感器测量平台不同方向。一次性得出平台与基准面之间的面夹角及面夹角的方向。重力传感器在手机横竖的时候可以实现屏幕自动翻转，在玩游戏时可以代替上下左右，比如在玩赛车游戏，可以不通过按键，将手机平放，左右摇摆就可以代替模拟机游戏的方向左右移动，目前已被互联网应用公司用于开发出“摇一摇”、“甩歌甩屏”、“翻转静音”等功能，已成为目前智能手机的标准配置。    (2)距离传感器    距离传感器又叫位移传感器，是通过发射特别短的光脉冲，将该变化量换算为距离，测量从传感器到对象物的距离位移的机器。根据使用元件不同，分为光学式位移传感器、线性接近传感器、超声波位移传感器等。距离感应器一般都在手机听筒的两侧或者是在手机听筒凹槽中，这样便于它的工作。例如，当用户在接听或拨打电话时，将手机靠近头部。距离感应器可以测出手机和头部之间的距离，该距离到了一定程度后，距离感应器便通知屏幕背景灯熄灭，拿开时再度点亮背景灯，这样方便用户操作，也可节省用电量。    (3)光线传感器    光线传感器也叫做亮度感应器(light-sensor)，由投光器及受光器所组成，利用投光器将光线由透镜聚焦，经传输至受光器的透镜，再至接收感应器，感应器将收到的光线信号转变成电器信号，此电器信号更可进一步做各种不同的开关及控制动作，其基本原理即对投光器受光器间的光线做遮蔽动作所获得的信号加以运用以完成各种自动化控制。它一般位于手持设备屏幕上方，能根据手持设备目前所处的光线亮度，自动调节手持设备屏幕亮度，给使用者带来最佳视觉效果。例如在黑暗的环境下，手持设备屏幕背光灯就会自动变暗，否则很刺眼。光线传感器在进入睡眠模式的时候，会发出蓝色周期性闪动的光，帮助用户在夜间寻找手机。    (4)陀螺仪    陀螺仪(gyroscope)是用高速回转体的动量矩敏感壳体相对惯性空间绕正交于自转轴的一个或二个轴的角运动检测装置。是苹果公司在iPhone 4设备中引入的一项重要能力。目前在移动终端中主要配置三轴陀螺仪，可以感知横竖纵3个方向的位置变化。三轴陀螺仪最大的作用就是测量角速度，以判别物体的运动状态，所以也称为运动传感器，目前在iPhone中用于帮助稳定视频拍摄，在很多射击类游戏中广泛采用。    另外，在其他新型交互技术方面，三星已在欧洲申请了商标“Eye Scroll”，在Galaxy S III上采用了眼球跟踪技术“Smart Stay”，能够避免手机进人睡眠的状态，通过前置摄像头判断用户是否在看手机屏幕，以响应眼球运动。谷歌眼镜则靠轻微的摇头晃脑来实现鼠标的滑动及按键功能，通过语音与多种交互技术的结合，实现眼镜的开关。可以预见，随着移动互联网深人渗透人们的生活，智能终端逐步向“穿戴式”发展，各种新型的人机交互技术也必将不断涌现。